{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202c1813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime \n",
    "\n",
    "airports_codes = ['TLV', 'LHR', 'MAD', 'JFK', 'CDG', 'FCO', 'ATH', 'AMS', 'FRA']\n",
    "dataset = pd.read_csv(\"raw_data.csv\")\n",
    "                         \n",
    "# Extract airport codes from 'Origin' and 'Destination' columns, filter bad values\n",
    "dataset['OriginCode'] = dataset['Origin'].str.extract('\\((.*?)\\)')\n",
    "dataset['DestinationCode'] = dataset['Destination'].str.extract('\\((.*?)\\)')\n",
    "dataset = dataset[dataset['OriginCode'].isin(airports_codes) & dataset['DestinationCode'].isin(airports_codes)]\n",
    "\n",
    "# extract the aircraft code\n",
    "dataset = dataset.assign(Aircraft_Code = dataset['Aircraft'].str.split('(').str[0])\n",
    "dataset['Aircraft_Code'] = dataset['Aircraft_Code'].str.replace(\" \", \"\")\n",
    "\n",
    "#extract the airline code, filter bad values\n",
    "dataset['Code_letters'] = dataset['Code'].str.extract('^([A-Z]+)')\n",
    "airlines_codes = ['DLH', 'KLM', 'AEE', 'BAW', 'IBE', 'DAL', 'AFR', 'ITY', 'ELY', 'DL', 'KL', 'AE', 'BA', 'IB', 'DA', 'AF', 'IT', 'EL']\n",
    "dataset = dataset[dataset['Code_letters'].isin(airlines_codes)]\n",
    "\n",
    "# Convert the time strings to datetime objects\n",
    "dataset['Scheduled Departure'] = pd.to_datetime(dataset['Scheduled Departure'], format='%H:%M')\n",
    "dataset['Actual Departure'] = pd.to_datetime(dataset['Actual Departure'], format='%H:%M', errors='coerce')\n",
    "\n",
    "# Add the offset column\n",
    "dataset['offset'] = dataset['Actual Departure'] - dataset['Scheduled Departure']\n",
    "\n",
    "# devide to 3 bins, to map dual hours sections of the day in which the flight is scheduled\n",
    "bin_start_1 = pd.to_datetime('00:00', format='%H:%M')\n",
    "bin_end_1 = pd.to_datetime('00:59', format='%H:%M')\n",
    "bins = [bin_start_1,bin_end_1]\n",
    "labels = [0]\n",
    "for i in range(1,24):\n",
    "    if i<10:\n",
    "        str1='0'+str(i)+':00'\n",
    "    else:\n",
    "        str1=str(i)+':00' \n",
    "    bin1 = pd.to_datetime(str1, format='%H:%M')\n",
    "    bins.append(bin1)\n",
    "    labels.append(i)\n",
    "\n",
    "bins.sort()\n",
    "dataset['time_bin'] = pd.cut(dataset['Scheduled Departure'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "#Convert the time columns back to string and format them, filter bad values\n",
    "dataset['Scheduled Departure'] = dataset['Scheduled Departure'].dt.strftime('%H:%M')\n",
    "dataset['Actual Departure'] = dataset['Actual Departure'].dt.strftime('%H:%M')\n",
    "dataset['offset1'] = pd.to_timedelta(dataset['offset'])\n",
    "dataset['offset_minutes'] = dataset['offset1'].dt.total_seconds() / 60\n",
    "dataset = dataset.drop('offset1', axis=1)\n",
    "offset_hours = dataset['offset'].dt.total_seconds() / 3600\n",
    "offset_hours1 = dataset['offset'].dt.total_seconds() / 3600\n",
    "dataset['offset']  = offset_hours.fillna(0).apply(lambda x: '{:02d}:{:02d}'.format(int(x), int((x % 1) * 60)))\n",
    "dataset[dataset['offset']>\"20:00\"]\n",
    "dataset=dataset.drop(dataset[dataset['offset']>\"20:00\"].index)\n",
    "\n",
    "#Convert aircraft to maximum seats possible\n",
    "seats_dict = {'B788': 330,\n",
    "              'B789': 350,\n",
    "              'B772': 380,\n",
    "              'A35K': 440,\n",
    "              'B77W': 440,\n",
    "              'A388': 853,\n",
    "              'B744': 660,\n",
    "              'A332': 440,\n",
    "              'A359': 440,\n",
    "              'A333': 440,\n",
    "              'A339': 440,\n",
    "              'B764': 440,\n",
    "              'B763': 440,\n",
    "              'A321': 220,\n",
    "              'B739': 150,\n",
    "              'A320': 150,\n",
    "              'A21N': 150,\n",
    "              'A20N': 150,\n",
    "              'A319': 150,\n",
    "              'A318': 150,\n",
    "              'B738': 150,\n",
    "              'B737': 150,\n",
    "              'E190': 100,\n",
    "              'E75L': 70,\n",
    "              'E295': 90,\n",
    "              'BCS3': 80,\n",
    "              'E170': 70,\n",
    "              'CRJX': 70,\n",
    "              'B78X': 70,\n",
    "              'J328': 50,\n",
    "              'B752': 220}\n",
    "dataset['Aircraft_Code'] = dataset['Aircraft_Code'].map(seats_dict)\n",
    "dataset = dataset.rename(columns={'Aircraft_Code': 'Aircraft_Seats'})\n",
    "\n",
    "airport_codes_dict = {'TLV' : 1,\n",
    "                      'LHR' : 2,\n",
    "                      'MAD' : 3,\n",
    "                      'JFK' : 4,\n",
    "                      'CDG' : 5,\n",
    "                      'FCO' : 6,\n",
    "                      'ATH' : 7,\n",
    "                      'AMS' : 8,\n",
    "                      'FRA' : 9}\n",
    "#Convert origin and destination to code\n",
    "#unique_values = dataset['OriginCode'].unique()\n",
    "#mapping_OriginCode = {value: index+1 for index, value in enumerate(unique_values)}\n",
    "dataset['OriginCode'] = dataset['OriginCode'].map(airport_codes_dict)\n",
    "    \n",
    "#unique_values = dataset['DestinationCode'].unique()\n",
    "#mapping_DestinationCode = {value: index+1 for index, value in enumerate(unique_values)}\n",
    "dataset['DestinationCode'] = dataset['DestinationCode'].map(airport_codes_dict)\n",
    "\n",
    "airlines_codes_dict = {'DLH' : 1, \n",
    "                       'KLM' : 2, \n",
    "                       'AEE' : 3, \n",
    "                       'BAW' : 4, \n",
    "                       'IBE' : 5, \n",
    "                       'DAL' : 6, \n",
    "                       'AFR' : 7, \n",
    "                       'ITY' : 8, \n",
    "                       'ELY' : 9, \n",
    "                       'DL' : 1, \n",
    "                       'KL' : 2, \n",
    "                       'AE' : 3, \n",
    "                       'BA' : 4, \n",
    "                       'IB' : 5, \n",
    "                       'DA' : 6, \n",
    "                       'AF' : 7, \n",
    "                       'IT' : 8, \n",
    "                       'EL' : 9}\n",
    "#unique_values = dataset['Code_letters'].unique()\n",
    "#mapping_Code_letters = {value: index+1 for index, value in enumerate(unique_values)}\n",
    "dataset['Code_letters'] = dataset['Code_letters'].map(airlines_codes_dict)\n",
    "\n",
    "#Output the relevant, relatively clean dataset\n",
    "dataset = dataset.drop(dataset.columns[0:9], axis=1)\n",
    "dataset = dataset.drop(dataset.columns[4], axis=1)\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "dataset.to_csv(\"clean_data.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
